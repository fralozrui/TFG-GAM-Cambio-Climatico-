---
author: "Francisco José Lozano Ruiz"
date: "27/10/2017"
documentclass: book
forprint: true  # true: imprime a dos caras, false: libro digital
fontsize: 12pt # 10pt,11pt
geometry: margin = 2.5cm 
bibliography: ["bib/library.bib", "bib/paquetes.bib"]
# metodobib -> true: natbib (descomentar: citation_package: natbib) 
#           -> false: pandoc (comentar: citation_package: natbib)
metodobib: true
#natbib: plainnat, abbrvnat, unsrtnat
biblio-style: "plainnat"
#Método 2 (pandoc): descomente una línea de las 2 siguientes en caso de usarlo
csl: methods-in-ecology-and-evolution.csl      # no numera mejor en las citas
#csl: acm-sig-proceedings-long-author-list.csl  # numera peor en las citas
link-citations: yes
output: 
  pdf_document:
    keep_tex: no
    number_sections: yes
    citation_package: natbib  # comentado usa: pandoc-citeproc
    #toc: yes
    fig_caption: yes
    template: latex/templateMemoriaTFE.tex
    includes:
      #before_body: portadas/latex_paginatitulo_modTFE.tex
      #in_header: latex/latex_preambulo.tex
      #after_body: latex/latex_antes_enddoc.tex
---

```{r include=FALSE}
knitr::opts_chunk$set(fig.path = 'figurasR/',
                      echo = FALSE, warning = FALSE, message = FALSE,
                      fig.pos="H",fig.align="center",out.width="95%",
                      cache=FALSE)

```

<!-- \setcounter{chapter}{2} -->

<!-- \setcounter{chapter}{2} escribir 2 para capítulo 3  -->

<!-- \pagenumbering{arabic} -->

```{=tex}
\ifdefined\ifprincipal
\else
\setlength{\parindent}{1em}
\pagestyle{fancy}
\setcounter{tocdepth}{4}
\tableofcontents
```
<!-- \nocite{*} -->

\fi

```{=tex}
\ifdefined\ifdoblecara
\fancyhead{}{}
\fancyhead[LE,RO]{\scriptsize\rightmark}
\fancyfoot[LO,RE]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[LE,RO]{\footnotesize\thepage}
\else
\fancyhead{}{}
\fancyhead[RO]{\scriptsize\rightmark}
\fancyfoot[LO]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[RO]{\footnotesize\thepage}
\fi
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
```
\theoremstyle{remark}
\newtheorem{observación}{Observación}[section]
\theoremstyle{definition}
\newtheorem{definición}{Definición}[section]
\theoremstyle{definition}
\newtheorem{proposición}{Proposición}[section]
\theoremstyle{remark}
\newtheorem{ejemplo}{Ejemplo}[section]

# Modelos lineales generalizados

## Introducción

Los modelos estadísticos pretenden explicar la relación entre dos o mas variables, en particular, tratan de describir el comportamiento de una variable respuesta (o dependiente), que se suele denotar por $Y$, mediante la información que otorgan las variables predictoras (o independientes), que se suelen denotar como $X_{1},...,X_{p}$.

Como se indica en @Stat-Learning, la forma más general de expresar matemáticamente los modelos estadísticos es la siguiente: 
\begin{equation}
Y = f(X_{1},..,X_{p}) + \epsilon
\label{eq:modelo general}
\end{equation}

Donde $f$ es una función desconocida cuyo propósito es el de representar de la mejor[^1] manera posible la relación entre las variables $X_{1},...,X_{p}$ e $Y$; y $\epsilon$ es un error aleatorio independiente de las variables predictoras que deberá cumplir ciertas condiciones según el tipo de modelo que estemos tratando. 

[^1]: El cómo de bueno es un modelo es un concepto que se puede definir de tantas formas como maneras hay de evaluarlos. Veremos varias de ellas a lo largo del trabajo.

Este trabajo tiene como finalidad el definir un conjunto de estrategias y técnicas que proporcionan un ajuste óptimo de la función $f$, es decir, que asemeje lo mejor posible la relación de las variables al fenómeno que se esté estudiando. Además, se incluye una posterior aplicación práctica de dichos resultados en el ámbito del cambio climático.

En lo que a este capítulo respecta, partiremos definiendo los modelos lineales de una forma breve y más general, ya que se ve de manera más extensa en varias asignaturas durante el grado. Tras ello, daremos varios resultados básicos para el entendimiento y desarrollo de los Modelos Lineales Generalizados.

\newpage
## Modelos lineales

El modelo lineal ocupa un lugar clave en el manual de herramientas de todo estadístico aplicado. Esto se debe a su simple estructura, a la fácil interpretación de sus resultados y al sencillo desarrolo de la teoría de mínimos cuadrados. Sin embargo, a la hora de dar su definición se deben tener en cuenta ciertas restricciones que deben cumplir las variables y los errores del modelo. Estas condiciones hacen que el modelo no sea capaz de adaptarse bien a todos los fenómenos que uno propone describir con él pero, a cambio, otorga esa sencillez de visualización antes mencionada. Daremos a continuación una serie de definiciones y resultados basados en @Wood. 


\begin{definición}[Modelo Lineal]
Sean $X_{1},\dots,X_{p}$ un conjunto de p vectores aleatorios de n componentes (con $p \leqslant n$) e $Y = (Y_{1},\dots,Y_{n})^T$ un vector aleatorio de n componentes tal que $E[Y]=\mu$. Entonces, se entiende por modelo lineal (multivariante) aquel que determina la relación entre los vectores aleatorios mediante una combinación lineal de parámetros de la siguiente forma:
$$
\mu = X\beta
$$
$$ 
Y = \mu + \epsilon
$$
O vectorialmente como: 
$$ 
\begin{pmatrix} Y_{1} \\ \vdots \\ Y_{i} \\ \vdots \\ Y_{n} \end{pmatrix} = 
\begin{pmatrix} x_{(1,1)} & \dotsb & x_{(1,j)} & \dotsb & x_{(1,p)} \\
                 \dotsb & \ddots & \vdots & \ddots & \dotsb \\
                 x_{(i,1)} & \dotsb & x_{(i,j)} & \dotsb & x_{(i,p)} \\
                 \dotsb & \ddots & \vdots & \ddots & \dotsb \\
                 x_{(n,1)} & \dotsb & x_{(n,j)} & \dotsb & x_{(n,p)}
\end{pmatrix}
\begin{pmatrix} \beta_{1} \\ \vdots \\ \beta_{i} \\ \vdots \\ \beta_{p} \end{pmatrix}
+
\begin{pmatrix} \epsilon_{1} \\ \vdots \\ \epsilon_{i} \\ \vdots \\ \epsilon_{n} \end{pmatrix}
$$
\label{modelo-lineal}
\end{definición}

Donde: 
\begin{itemize}
  \item $\beta$ es un vector de parámetros $\beta_i$ a determinar que reflejan la magnitud del efecto lineal (constante) de los incrementos unitarios en las variables explicativas $X_{i}$ sobre la variable explicada $Y$.
  \item $\epsilon$ es un vector aleatorio tal que los $\epsilon_{i}$ son variables aleatorias independientes e identicamente distribuidas por una distribución normal de esperanza nula y varianza $\sigma^2$ ($\epsilon_{i} \backsim N(0,\sigma^2)$). Representa el término de error del modelo y corresponde con $\epsilon = Y-E[Y]$.
\end{itemize}
\begin{observación} Gracias a lo notado en el párrafo anterior podemos ver que: \newline $Y \backsim N(\mu,\sigma^2I_{n})$ ya que:
$$
E[Y] = E[X \beta + \epsilon] = X\beta + E[\epsilon] = X\beta = \mu
$$
$$
Cov(Y) = Cov(X\beta + \epsilon) = Cov(\epsilon) = \sigma^2I_{n}
$$
\end{observación}
Veamos ahora cómo se pueden obtener los valores de los parámetros $\beta$.
\begin{definición}[Estimador por mínimos cuadrados]
Elegiremos los valores de $\beta$ que minimicen la suma de cuadrados:
\begin{equation}
S =  \sum_{i=1}^n \epsilon_{i}^2 =  \sum_{i=1}^n (Y_{i}-\mu_{i})^2 = \sum_{i=1}^n (Y_{i}- (X\beta)_{i})^2
\label{eq:MinCuad}
\end{equation}
Es decir: 
$$
\hat{\beta} = arg_{\beta \in \mathbb{R}^p}min{||Y-X\beta||^2}
$$
Donde $||\cdot||$ denota la norma euclídea.
\label{minimos-cuadrados}
\end{definición}

Para encontrar tal mínimo se razona derivando respecto de cada $\beta_i$ y luego igualando a 0. De este modo los parámetros $\beta_i$ vienen dados por la solución del siguiente sistema:

$$ \left\{
\begin{array}{ l }
\frac{\partial S}{\partial \beta_1}= 0 \\
\dots \\
\frac{\partial S}{\partial \beta_p}= 0
\end{array}
\right. 
$$
Desarrollando este sistema de escuaciones llegamos a que es equivalente a $X^TX\hat{\beta} = X^TY$, por lo que el estimador por mínimos cuadrados del vector de parámetros $\beta$ viene dado por:
\begin{equation}
\hat{\beta} = (X^TX)^{-1}X^TY
\label{eq:EstMinCuad}
\end{equation}

\begin{observación} Notemos que esta expresión tiene sentido pues el producto $X^TX$ resulta en una matriz cuadrada de orden p y rango máximo, por lo que el sistema antes dado tiene solución única.
\end{observación}

\begin{proposición}[Distribución del estimador $\hat{\beta}$] 
El estimador por mínimos cuadrados del vector de parámetros $\beta$, $\hat{\beta}$, sigue una distribución del tipo normal p-variante de esperanza $\beta$ y matriz de covarianzas $V_{\hat{\beta}} = \sigma^2 (X^TX)^{-1}$. Es decir: 
$ \hat{\beta} \backsim N_{p}(\beta,\sigma^2 (X^TX)^{-1})$
\end{proposición}

\begin{proof}
Partiremos viendo que el estimador $\hat{\beta}$ es insesgado:
$$
E[\hat{\beta}] = E[(X^TX)^{-1}X^TY] = (X^TX)^{-1}X^TE[Y]=(X^TX)^{-1}X^TX \beta = \beta
$$
Por otro lado, calculemos  la matriz de covarianzas de $\hat{\beta}$, para ello primero debemos notar que como los errores aleatorios $\epsilon_i$ son independientes e identicamentes distribuidos con esperanza nula y varianza $\sigma^2$, $\forall i \neq j$:
$$
E[\epsilon_i \epsilon_j] = E[\epsilon_i] + E[\epsilon_j] + Cov(\epsilon_i, \epsilon_j) = 0 
$$
y, por tanto:
$$
E[\epsilon \epsilon^T] = 
E\begin{bmatrix}
\epsilon_1^2 & \epsilon_1 \epsilon_2 & \dotsb & \epsilon_1 \epsilon_n \\
\epsilon_1 \epsilon_2 & \epsilon_2^2 & \dotsb & \epsilon_2 \epsilon_n \\
\vdots &\vdots & \ddots & \vdots \\
\epsilon_1 \epsilon_n & \dotsb & \dotsb & \epsilon_n^2
\end{bmatrix}
= 
\begin{pmatrix}
E[\epsilon_1^2] & E[\epsilon_1 \epsilon_2] & \dotsb & E[\epsilon_1 \epsilon_n] \\
E[\epsilon_1 \epsilon_2] & E[\epsilon_2^2] & \dotsb & E[\epsilon_2 \epsilon_n] \\
\vdots &\vdots & \ddots & \vdots \\
E[\epsilon_1 \epsilon_n] & \dotsb & \dotsb & E[\epsilon_n^2]\end{pmatrix}
= 
\begin{bmatrix}
\sigma^2 & 0 & \dotsb & 0 \\
0 & \sigma^2 & \dotsb & 0 \\
\vdots &\vdots & \ddots & \vdots \\
0 & \dotsb & \dotsb & \sigma^2
\end{bmatrix}
$$
Luego, utilizando que por $\ref{eq:EstMinCuad}$ se tiene que $\hat{\beta} = \beta + (X^TX)^{-1}X \epsilon$, obtenemos que la matriz de covarianzas es: 

\begin{equation*}
\begin{split}
Cov(\hat{\beta}) & = E[(\hat{\beta} - E[\hat{\beta}])(\hat{\beta} - E[\hat{\beta}])^T] = 
E[(\hat{\beta} - \beta)(\hat{\beta} - \beta)^T] = \\ 
& = E[((X^TX)^{-1}X^T \epsilon)((X^TX)^{-1}X^T \epsilon)^T] = 
  E[(X^TX)^{-1}X^T \epsilon \epsilon^T X(X^TX)^{-T}] = \\
& = (X^TX)^{-1}X^T E[\epsilon \epsilon^T] X(X^TX)^{-T} = 
  (X^TX)^{-1}X^T \sigma^2 I_n X(X^TX)^{-T} = \\
& = \sigma^2 (X^TX)^{-1}X^T X(X^TX)^{-T} =\sigma^2 (X^TX)^{-1}
\end{split}
\end{equation*}

Acabamos la prueba recordando que $\hat{\beta}$ no es más que una combinación lineal de variables aleatorias normales, concretamente de las $Y_i$, para decir que en efecto sigue una distribución normal p-variante como indica el enunciado.
\end{proof}

\begin{observación}
Ahora bien, generalmente el valor de $\sigma^2$ es desconocido así que también sería preciso dar una estimación del mismo para que así los resultados anteriores fueran de alguna utilidad.
\end{observación}

\begin{definición}[Estimador de $\sigma^2$]
La varianza $\sigma^2$ admite un estimador insesgado que se basa en la suma de cuadrados:
$$
\hat{\sigma}^2 = \frac{S}{n-p}= \frac{\sum_{i=1}^n (Y_{i}- (X\beta)_{i})^2}{n-p}
$$
Además se tiene que $\hat{\sigma}^2$ sigue una distribución: 
$$
\hat{\sigma}^2 \backsim \frac{\sigma^2}{n-p}\chi^2_{n-p}
$$
\end{definición}

\begin{observación}
No daremos la obtención de este estimador pero sí indicaremos que su distribución se obtiene directamente de que como S es la suma de normales $N(0,\sigma^2)$ y $\frac{\epsilon_i}{\sigma} \backsim N(0,1)$, entonces: $\frac{1}{\sigma^2}S \backsim \chi^2_{n-p}$. Finalmente, multiplicando y dividiento esta expresión por (n-p) y sustituyendo la definición del estimador $\hat{\sigma}^2$ obtenemos el resultado.
\end{observación}

## Modelos lineales generalizados

Nos adentramos ya con esta sección en la primera extensión de los modelos lineales de las que se tratan durante el trabajo. Los Modelos Lineales Generalizados (MLG) fueron originalmente formulados por John Nelder y Robert Wedderburn (1972), quienes tenían como propósito unificar varios modelos estadísticos como la regresión lineal, la logística y la de Poisson en un mismo modelo. Este tipo de modelo relaja algunas de las hipótesis que asumían los modelos lineales, como que los errores ya no deben seguir ninguna distribución específica, y además añade nuevos elementos como la función de enlace, la cual interviene en la relación entre los valores esperados y la forma lineal del modelo. También se deberá tener en cuenta una nueva hipótesis distribucional, las variables de respuestas seguirán distribuciones de tipo exponencial. Más tarde introduciremos cada uno de estos aspectos, de momento demos la estructura básica de un MLG como en @Wood.

\begin{definición}[Estructura básica de un MLG]

$$
\mu = \begin{pmatrix} \mu_1 \\ \vdots \\ \mu_n \end{pmatrix} = 
\begin{pmatrix} E[Y_1] \\ \vdots \\ E[Y_n] \end{pmatrix} = E[Y]
$$
$$
g(\mu_i) = X_i\beta , \hspace{0.5cm} \forall i =1,\dots,n
$$

Donde: 
\begin{itemize}
  \item X es la matriz modelo de dimensión $n \times p$ con $p \leqslant n$, que contiene a las variables predictoras, cada columna representa una variable predictora $X_i$.
  \item $\beta = (\beta_1,\dots,\beta_p)^T$ es el vector de parámetros desconocidos como en el caso de los modelos lineales. A $\eta = X\beta$ se le conoce como predictor lineal.
  \item $g: \mathbb{R} \rightarrow \mathbb{R}$ es la función de enlace, que debe ser diferenciable y monótona. Representa la relación entre la media de las variables de respuesta y el predictor lineal.
  \item $Y=(Y_1,\dots,Y_n)^T$ es un vector aleatorio, se suele suponer que las $Y_i$ son variables aleatorias independientes y que siguen una distribución de tipo exponencial.
\end{itemize}
\label{Estructura básica de un MLG}
\end{definición}


\begin{observación}
Desde esta formulación podemos ver fácilmente el por qué decimos que los MLG son una generalización de los modelos lineales, ya que basta tomar a la identidad como la función de enlace y suponer que la distribución considerada sea de tipo normal para encontrarnos ante la forma general de un modelo lineal como vimos en la sección anterior.
\end{observación}

### Familia de distribuciones exponenciales

Como hemos mencionado antes, la variable de respuesta de los modelos lineales generalizados deben seguir una distribución de tipo exponencial, en esta sección veremos qué significa eso y qué implicaciones tiene. Uno de los motivos más importantes por los que se supone que las variables de respuesta $Y_i$ siguen distribuciones de esta familia se debe a que en los modelos lineales los cambios constantes en las variables predictoras implicaban cambios constantes en la variable de respuesta, pero ahora se quiere permitir que dichos cambios constantes de entrada puedan implicar también variaciones geométricas. @MLG-wikipedia.

\begin{definición}[Distribución de tipo exponencial]
Una distribución se dice que es de tipo exponencial si su función de densidad es de la forma: 
$$
f_{\theta}(y) = e^{\frac{y\theta - b(\theta)}{a(\phi)}+c(y,\phi)}
$$
Donde: 
\begin{itemize}
  \item a, b y c son funciones arbitrarias.
  \item  $\phi$ es conocido como parámetro de escalado.
  \item $\theta$ es conocido como parámetro canónico de la distribución. Más adelante veremos que depende completamente de los parámetros del modelo $\beta$.
\end{itemize}
\end{definición}

\begin{ejemplo}
La distribución normal es de tipo exponencial pues su función de densidad es:
$$
f_{\mu}(y) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(y-\mu)^2}{2\sigma^2}} = 
e^{\frac{-y^2+2y\mu-mu^2}{2\sigma^2}-log(\sigma\sqrt{2\pi})} = 
e^{\frac{y\mu-\mu^2/2}{\sigma^2}-\frac{y^2}{2\sigma^2}-log(\sigma\sqrt{2\pi})}
$$
Y por tanto toma los siguientes parámetros de la familia exponencial:
\begin{itemize}
  \item $\theta = \mu$
  \item $b(\theta) = \frac{\theta^2}{2} = \frac{\mu^2}{2}$
  \item $a(\phi) = \phi = \sigma^2$
  \item $c(\phi,y) = \frac{-y^2}{2\phi}-log(\sqrt{\phi 2 \pi}) = \frac{-y^2}{2\sigma} - log(\sigma \sqrt{2\pi})$
\end{itemize}
\end{ejemplo}

Es posible dar una forma general para la esperanza y la varianza de las variables de tipo exponencial dependiendo de los parámetros de su función de densidad. Lo vemos en el siguiente resultado.

\begin{proposición}
Sea Y una variable de tipo exponencial, entonces verifica:

\begin{equation} E[Y] = b'(\theta) \label{Esperanza exponencial}\end{equation}
\begin{equation} Var(Y) = b''(\theta)a(\phi) \label{Varianza exponencial}\end{equation}

\end{proposición}

\begin{proof}
Partimos considerando la función de verosimilitud logáritmica para $\theta$:
$$
l(\theta) = log(f_{\theta}(y)) = \frac{y\theta - b(\theta)}{a(\phi)} + c(y,\phi)
$$
Y su derivada respecto de theta: 
$$
\frac{\partial l}{\partial \theta}(\theta) =\frac{y-b'(\theta)}{a(\phi)} 
$$
Ahora bien, si cambiamos la observación y por la variable Y, podemos evaluar la esperanza de esta derivada, la cual será 0 por propiedades de la función de verosimilitud logáritmica.
$$
E[\frac{\partial l}{\partial \theta}(\theta)] = \frac{E[Y]-b'(\theta)}{a(\phi)} = 0
$$
Y de aquí se obtiene directamente que $E[Y] = b'(\theta)$.
Seguimos derivando para obtener que: 
$$
\frac{\partial^2 l}{\partial \theta^2}(\theta) =-\frac{b''(\theta)}{a(\phi)} 
$$
Y utilizando que: $E[\frac{\partial^2 l}{\partial \theta^2}] = -E[(\frac{\partial l}{\partial \theta})^2]$, nos queda que: 
$$
\frac{b''(\theta)}{a(\phi)} = \frac{E[(Y-b'(\theta))^2]}{a(\phi)^2} = \frac{E[(Y-E[Y])^2]}{a(\phi)^2} = \frac{Var(Y)}{a(\phi)^2}
$$
De donde se obtiene que: $Var(Y) = b''(\theta)a(\phi)$.
\end{proof}

\begin{observación}
Cuando $\phi$ es conocido el manejo de la función $a$ no tiene dificultad, pero en muchos casos $\phi$ suele ser desconocido, así que para agilizar los resultados escribiremos $a(\phi) = \frac{\phi}{\omega}$, donde ${\omega}$ es una constante conocida. De hecho, como se indica en @Wood, todos los casos prácticos de interés se podrán expresar así y la mayoría con ${\omega}=1$. De este modo nos queda: $Var(Y) = b''(\theta)\frac{\phi}{\omega}$.
Por otro lado, en secciones posteriores necesitaremos trabajar con Var(Y) en función de $\mu = E[Y]$, para ello utilizaremos la relación $\ref{Esperanza exponencial}$ y definiremos una nueva función: \begin{equation} V(\mu) = \frac{b''(\theta)}{\omega} \label{V} \end{equation} pues de este modo se tiene que: $Var(Y) = V(\mu)\phi$. @Wood.
\end{observación}

Podemos recoger las carácterísticas de las principales distribuciones de tipo exponencial en la siguiente tabla:

|  	| Binomial $Bi(n,p)$ 	| Normal $N(\mu,\sigma^2)$ 	|  Poisson $\newline$ $Po(\lambda)$ 	| Gamma $Ga(p,\lambda)$ 	|
|---	|---	|---	|---	|---	|
| $\theta(\mu)$ 	| $log(\frac{\mu}{n-\mu})$ 	| $\mu$ 	| $log(\mu)$ 	| $-\frac{1}{\mu}$ 	|
| $\phi$ 	| 1 	| $\sigma^2$ 	| 1 	| $\frac{1}{p}$ 	|
| $a(\phi)$ 	| 1 	| $\sigma^2$ 	| 1 	| $\frac{1}{p}$ 	|
| $b(\theta)$ 	| $nlog(1+e^{\theta})$ 	| $\frac{\theta^2}{2}$ 	| $e^{\theta}$ 	| $-log(-\theta)$ 	|
| $c(y,\phi)$ 	| $log(\binom{n}{y})$ 	| $-\frac{1}{2}(\frac{y^2}{\phi}+log(2\pi \phi))$ 	| $-log(y!)$ 	| $plog(py)-log(y\Gamma(p))$ 	|


### Ajuste de los modelos lineales generalizados

La estimación de parámetros e inferencia con modelos aditivos generalizados se basa en la estimación de máxima verosimilitud, ya que, gracias a la hipótesis de que las $Y_i$ pertenecezcan a la familia de distribuciones exponenciales, siempre se dispondrá de funciones de densidad. Partiremos considerando un MLG como el de la definición $\ref{Estructura básica de un MLG}$ y nuestro principal objetivo en esta sección será dar el estimador de máxima verosimilitud del vector de parámetros $\beta$ como se hace en @Wood. Veremos que será necesario recurrir a un algoritmo basado en mínimos cuadrados para hallar tal máximo, el método de mínimos cuadrados reponderados iterativamente.

Empezamos considerando $y$ una observación de $Y$ y notando que, como los $Y_i$ son independientes entre sí, en tal caso la función de verosimilitud para $\beta$ viene dada por: 
$$
L(\beta) = \prod_{i=1}^n f_{\theta_i}(y_i)
$$
Y la función de verosimilitud logarítmica:
$$
 l(\beta) = \sum_{i=1}^n log(f_{\theta_i}(y_i)) = \sum_{i=1}^n \frac{y_i\theta_i - b_i(\theta_i)}{a_i(\phi)}+c_i(\phi,y_i)
$$

La dependencia de $\beta$ viene de que $\theta$ depende de $\mu$ y este a su vez depende del predictor lineal. Ahora bien, si sustituimos en esta expresión que $a_i(\phi)= \frac{\phi}{\omega_i}$, como mencionamos en la sección anterior, nos queda:
$$
l(\beta) = \sum_{i=1}^n \omega_i\frac{y_i\theta_i - b_i(\theta_i)}{\phi}+c_i(\phi,y_i)
$$
Como queremos hallar el $\beta$ que la hace máxima derivamos respecto $\beta_i$ e igualamos a 0: 

$$
\frac{\partial l}{\partial \beta_j} = \frac{1}{\phi} \sum_{i=1}^n \omega_i(y_i\frac{\partial\theta_i}{\partial \beta_j} - b'_i(\theta_i)\frac{\partial\theta_i}{\partial \beta_j})
$$
Donde $\frac{\partial\theta_i}{\partial \beta_j}$ por la regla de la cadena es: 
$$
\frac{\partial\theta_i}{\partial \beta_j} = \frac{d\theta_i}{d \mu_i} \frac{\partial\mu_i}{\partial \beta_j} = \frac{d\theta_i}{d \mu_i} \frac{\partial\eta_i}{\partial \beta_j} \frac{\partial\mu_i}{\partial \eta_i} = \frac{X_{ij}}{g'(\mu_i) b''(\theta_i)}
$$
Hemos utilizado que $\frac{\partial\mu_i}{\partial \eta_i} = g'(\mu_i)$, que $\frac{\partial\eta_i}{\partial \beta_j} = X_{ij}$ y que derivando el resultado $\ref{Esperanza exponencial}$ se tiene: $\frac{d\theta_i}{d \mu_i} = \frac{1}{b''(\theta)}$. Sustituyendo también el resultado de $\ref{V}$: 
\begin{equation}
\frac{\partial l}{\partial \beta_j} = \frac{1}{\phi} \sum_{i=1}^n \frac{y_i - b'_i(\theta_i)}{g'(\mu_i)b''_i(\theta_i)/\omega_i} = 
\frac{1}{\phi} \sum_{i=1}^n \frac{y_i - \mu_i}{g'(\mu_i)V(\mu_i)}X_{ij}
\label{derivada log-likelihood}
\end{equation}

\begin{observación}
Ahora bien, el razonamiento general que seguiríamos sería el igualar estas derivadas a 0 y resolver el sistema resultante, sin embargo, se trata de un sistema con ecuaciones no lineales, por lo que para resolverlo utilizaremos métodos numéricos, en concreto utilizaremos el método de Newton que precisa del gradiente y del Hessiano de $l$. Por lo que debemos volver a derivar $l$.
\end{observación}
$$
\frac{\partial^2 l}{\partial \beta_j \beta_k} =  
-\frac{1}{\phi} \sum_{i=1}^n \frac{X_{ij}X_{ik}\alpha(\mu_i)}{g'(\mu_i)^2V(\mu_i)}
$$
Donde $\alpha(\mu_i) = 1 + (y_i - \mu_i)(\frac{V'(\mu_i)}{V(\mu_i)} + \frac {g''(\mu_i)}{g'(\mu_i)})$. Luego, si definimos la matriz $W = diag(\omega_i)$ para $\omega_i = \frac {\alpha(\mu_i)}{g'(\mu_i)^2V(\mu_i)}$, el Hessiano de $l$ es: $-\frac{1}{\phi}XWX$. De manera similar, si definimos $G = diag(\frac{g'(\mu)} {\alpha(\mu_i)})$, el gradiente de $l$ puede escribirse como: $X^TWG\frac{(y-\mu)}{\phi}$.

De este modo, una actualización del método de Newton es de la forma:
$$
\beta^{k+1} = \beta^k + (XWX)^{-1}X^TWG(y-\mu)= (XWX)^{-1}X^TWz
$$
Donde $z_i = g'(\mu_i) \frac{y_i-\mu_i}{\alpha(\mu_i)} + \eta_i$

\begin{observación} 
De lo anterior podemos notar que las actualizaciones de los $\beta^k$ no son más que las estimaciones de $\beta$ por mínimos cuadrados ponderados, es decir, resultan de minimizar:
\begin{equation}
\sum_{i=1}^n \omega_i(z_i - X_i\beta)^2
\label{minimos cuadrados ponderados}
\end{equation}
Podemos entonces obtener el estimador numérico de los parámetros $\beta$ de los MLG mediante el siguiente algoritmo.
\end{observación}

\begin{definición}[Algoritmo de mínimos cuadrados reponderados iterativamente]

1) Inicialización: tomar $\hat{\mu_i} = y_i + \delta_i$ y $\hat{\eta_i} = g(\hat{\mu_i})$, donde $\delta_i$ suele ser 0 o una constante que asegure que  $\hat{\eta_i}$ sea finito. \newline
2) Calcular: $z_i = g'(\mu_i) \frac{y_i-\hat{\mu_i}}{\alpha(\mu_i)} + \hat{\eta_i}$ y $\omega_i = \frac {\alpha(\hat{\mu}_i)}{g'(\hat{\mu}_i)^2V(\hat{\mu}_i)}$ \newline
3) Encontrar $\hat{\beta}$ el parámetro que minimiza la función objetivo de mínimos cuadrados ponderados $\ref{minimos cuadrados ponderados}$ y actualizar $\hat{\eta} = X \hat{\beta}$ y 
$\hat{\mu_i} = g^{-1}(\hat{\eta}_i)$
\end{definición}

\begin{observación}
Para saber con qué iteracion quedarnos debemos comprobar paso a paso si la variación entre el valor antiguo y el nuevo de $\hat{\beta}$ o las derivadas de la función de verosimilitud logáritmica están lo suficientemente cerca de 0.
\end{observación}

### Funciones de enlace canónicas

\begin{definición}[Funciones de enlace canónicas]
Se dice que una función de enlace $g_c$ es canónica para una distribución de la familia exponencial si verifica: $g_c(\mu_i)=\theta_i$, es decir, relaciona directamente el parámetro canónico con el predictor lineal.
\end{definición}

\begin{proposición}[Propiedades de las funciones de enlace canónicas]
\begin{itemize}
  \item Su uso en el modelo $\ref{Estructura básica de un MLG}$ resulta en: $\theta_i = X_i\beta$
  \item Hacen que $\alpha(\mu_i)=1$.
  \item El Hessiano de la función de verosimilitud logarítmica coincida con su valor esperado.
  \item El sistema a resolver para obtener los estimadores de máxima verosimilitud de $\beta$, es decir, el formado por las derivadas parciales $\frac{\partial l}{\partial \beta_j}$ igualadas a 0 se reduce a: $X^ty - X^T\hat{\mu} = 0 \Rightarrow X^ty = X^T\hat{\mu}$ pues $\frac{\partial \theta_i}{\partial \beta_j} = X_{ij}$
\end{itemize}
\end{proposición}

### Residuos

Al igual que para los modelos lineales, el estudio de los residuos $\epsilon_i$ de los MLG es un buen método para el control de los modelos, pero en este caso la estandarización de los residuos es necesaria y más complicada. Esto se debe a que si las suposiciones hechas sobre el modelo son correctas, entonces los residuos estandarizados deben tener aproximadamente la misma varizana y se deben comportar, tanto como sea posible, como los residuos de los modelos lineales. Para ello veremos dos tipos de estandarizaciones distintas.

\begin{definición} [Residuos de Pearson]
Se dividen los residuos entre una cantidad proporcional a la desviación estándar dada por el modelo ajustado: 
$$
\hat{\epsilon}^p_i = \frac{y_i - \hat{\mu_i}}{\sqrt{V(\hat{\mu_i})}}
$$
Deben tener media nula y varianza $\phi$ si el modelos es correcto.
\end{definición}

\begin{observación}
Estos residuos no deberían mostrar ninguna tendencia en la media o la varianza al representarlos frente a los valores ajustados del modelo. 
\end{observación}

En la práctica los residuos de Pearson suelen ser asimétricos en torno al 0, lo que no concuerda mucho con que se parezcan a los residuos de los modelos lineales. Por tanto, se considera también la siguiente estandarización de los residuos, que surge al comparar la desviación del MLG con la suma de los residuos al cuadrado de los modelos lineales. Veámos primero a qué nos referimos con desviación:

\begin{definición}[Desviación]
En el contexto de la definición $\ref{Estructura básica de un MLG}$, decimos que la desviación del modelo se define como:
\begin{equation}
D = 2(l(\hat{\beta}_{max})-l(\hat{\beta})\phi = 
\sum_{i=1}^n 2\omega_i(y_i(\tilde{\theta}_i - \hat{\theta}_i) - b(\tilde{\theta}_i + b(\hat{\theta}_i))
\label{eq:desviación}
\end{equation}
Donde:
\begin{itemize}
  \item $l(\hat{\beta}_{max})$ representa el valor máximo de la función de verosimilitud logarítmica del modelo saturado (el que tiene un parámetro por dato). Este es el valor máximo que pueden tener todas las funciones de verosimilitud logarítmicas para los datos dados.
  \item $\tilde{\theta}_i$ es la estimación del parámetro canónico para el modelo saturado.
  \item $\hat{\theta}_i$ es la estimación del parámetro canónico del modelo que estamos estudiando.
\end{itemize}
\end{definición}

\begin{definición}[Residuos de desviación]
Si denotamos por $d_i$ a la i-ésima componente de la desviación de un MLG, nos queda que $D = \sum_{i=1}^n d_i$ y se definen los residuos de desviación como:
$$
\hat{\epsilon}^d_i = signo(y_i - \hat{\mu_i})\sqrt{d_i}
$$
\end{definición}

\begin{observación}
Obviamente se tiene que: $ D = \sum_{i=1}^n (\hat{\epsilon}^d_i)^2$. Además, notemos que: $D^* = \frac{D}{\phi} \backsim \chi_n^2$ y, aunque esto no se pueda trasladar directamente componente a componente, podemos intuir que: 
$$
\frac{d_i}{\phi} \backsim \chi_1^2 \Rightarrow \hat{\epsilon}^d_i \backsim N(0,\phi)
$$
Es decir, intuitivamente, se comportarán como los residuos de los modelos lineales.
\end{observación}