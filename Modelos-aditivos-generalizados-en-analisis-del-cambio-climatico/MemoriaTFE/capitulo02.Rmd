---
author: "Nombre Completo Autor"
date: "27/10/2017"
documentclass: book
forprint: true  # true: imprime a dos caras, false: libro digital
fontsize: 12pt # 10pt,11pt
geometry: margin = 2.5cm 
bibliography: ["bib/library.bib", "bib/paquetes.bib"]
# metodobib -> true: natbib (descomentar: citation_package: natbib) 
#           -> false: pandoc (comentar: citation_package: natbib)
metodobib: true
#natbib: plainnat, abbrvnat, unsrtnat
biblio-style: "plainnat"
#Método 2 (pandoc): descomente una línea de las 2 siguientes en caso de usarlo
csl: methods-in-ecology-and-evolution.csl      # no numera mejor en las citas
#csl: acm-sig-proceedings-long-author-list.csl  # numera peor en las citas
link-citations: yes
output: 
  pdf_document:
    keep_tex: no
    number_sections: yes
    citation_package: natbib  # comentado usa: pandoc-citeproc
    #toc: yes
    fig_caption: yes
    template: latex/templateMemoriaTFE.tex
    includes:
      #before_body: portadas/latex_paginatitulo_modTFE.tex
      #in_header: latex/latex_preambulo.tex
      #after_body: latex/latex_antes_enddoc.tex
---

```{r include=FALSE}
knitr::opts_chunk$set(fig.path = 'figurasR/',
                      echo = FALSE, warning = FALSE, message = FALSE,
                      fig.pos="H",fig.align="center",out.width="95%",
                      cache=FALSE)

```

<!-- \setcounter{chapter}{2} -->

<!-- \setcounter{chapter}{2} escribir 2 para capítulo 3  -->

<!-- \pagenumbering{arabic} -->

```{=tex}
\ifdefined\ifprincipal
\else
\setlength{\parindent}{1em}
\pagestyle{fancy}
\setcounter{tocdepth}{4}
\tableofcontents
```
<!-- \nocite{*} -->

\fi

```{=tex}
\ifdefined\ifdoblecara
\fancyhead{}{}
\fancyhead[LE,RO]{\scriptsize\rightmark}
\fancyfoot[LO,RE]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[LE,RO]{\footnotesize\thepage}
\else
\fancyhead{}{}
\fancyhead[RO]{\scriptsize\rightmark}
\fancyfoot[LO]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[RO]{\footnotesize\thepage}
\fi
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
```
\theoremstyle{remark}
\newtheorem{observación}{Observación}[section]
\theoremstyle{definition}
\newtheorem{definición}{Definición}[section]
\theoremstyle{plain}
\newtheorem{proposición}{Proposición}[section]
\theoremstyle{remark}
\newtheorem{ejemplo}{Ejemplo}[section]

# Modelos lineales generalizados

## Introducción

Como bien introdujimos antes, los modelos estadísticos pretenden explicar la relación entre dos o mas variables, en particular, tratan de describir el comportamiento de una variable respuesta (o dependiente), que se suele denotar por $Y$, mediante la información que otorgan las variables predictoras (o independientes), que se suelen denotar como $X_{1},...,X_{p}$.

La forma más general de expresar matemáticamente la intención de los modelos estadísticos es la siguiente: $$
  Y = f(X_{1},..,X_{p}) + \epsilon
  $$ Donde $f$ es una función desconocida cuyo propósito es el de representar de la "mejor"[^1] manera posible la relación entre las variables $X_{1},...,X_{p}$ e $Y$, y $\epsilon$ es un error aleatorio independiente de las variables predictoras que deberá cumplir ciertas condiciones según el tipo de modelo que estemos tratando.

[^1]: Escribimos mejor entre comillas pues hay diversas formas de evaluar los modelos.

Este trabajo tiene como finalidad el definir un conjunto de estrategias y técnicas que proporcionan un ajuste óptimo de la función $f$, es decir, que asemeje lo mejor posible la relación de las variables al fenómeno que se esté estudiando. Además, se incluye una posterior aplicación práctica de dichos resultados en el ámbito del cambio climático.

En lo que a este capítulo respecta, partiremos definiendo los modelos lineales de una forma breve y más general, ya que se ve de manera más extensa en varias asignaturas durante el grado. Tras ello daremos varios resultados básicos para el entendimiento y desarrollo de los Modelos Lineales Generalizados.

\newpage
## Modelos lineales

El modelo lineal ocupa un lugar clave en el manual de herramientas de todo estadístico aplicado. Esto se debe a su simple estructura, a la fácil interpretación de sus resultados y al sencillo desarrolo de la teoría de mínimos cuadrados. Sin embargo, a la hora de dar su definición se deben tener en cuenta ciertas restricciones que deben cumplir las variables y los errores del modelo. Estas condiciones hacen que el modelo no sea capaz de adaptarse bien a todos los fenómenos que uno se propone describir pero, a cambio, otorga esa sencillez de visualización antes mencionada.


\begin{definición}[Modelo Lineal]
Sean $X_{1},\dots,X_{p}$ un conjunto de p vectores aleatorios de n componentes (con $p \leqslant n$) e $Y = (Y_{1},\dots,Y_{n})^T$ un vector aleatorio de n componentes tal que $E[Y]=\mu$. Entonces, se entiende por modelo lineal (multivariante) aquel que determina la relación entre los vectores aleatorios mediante una combinación lineal de parámetros de la siguiente forma:
$$
\mu = X\beta
$$
$$ 
Y = \mu + \epsilon
$$
O vectorialmente como: 
$$ 
\begin{pmatrix} Y_{1} \\ \vdots \\ Y_{i} \\ \vdots \\ Y_{n} \end{pmatrix} = 
\begin{pmatrix} x_{(1,1)} & \dotsb & x_{(1,j)} & \dotsb & x_{(1,p)} \\
                 \dotsb & \ddots & \vdots & \ddots & \dotsb \\
                 x_{(i,1)} & \dotsb & x_{(i,j)} & \dotsb & x_{(i,p)} \\
                 \dotsb & \ddots & \vdots & \ddots & \dotsb \\
                 x_{(n,1)} & \dotsb & x_{(n,j)} & \dotsb & x_{(n,p)}
\end{pmatrix}
\begin{pmatrix} \beta_{1} \\ \vdots \\ \beta_{i} \\ \vdots \\ \beta_{p} \end{pmatrix}
+
\begin{pmatrix} \epsilon_{1} \\ \vdots \\ \epsilon_{i} \\ \vdots \\ \epsilon_{n} \end{pmatrix}
$$
\label{modelo-lineal}
\end{definición}

Donde: 
\begin{itemize}
  \item $\beta$ es un vector de $\beta_i$ parámetros a determinar que reflejan la magnitud del efecto lineal (constante) de los incrementos unitarios en las variables explicativas $X_{i}$ sobre la variable explicada $Y$.
  \item $\epsilon$ es un vector aleatorio tal que los $\epsilon_{i}$ son variables aleatorias independientes e identicamente distribuidas por una distribución normal de esperanza nula y varianza $\sigma^2$ ($\epsilon_{i} \backsim N(0,\sigma^2)$). Representa el término de error del modelo y corresponde con $\epsilon = Y-E[Y]$.
\end{itemize}
\begin{observación} Gracias a lo notado en el párrafo anterior podemos ver que: $Y \backsim N(\mu,\sigma^2I_{n})$ ya que:
$$
E[Y] = E[X \beta + \epsilon] = X\beta + E[\epsilon] = X\beta = \mu
$$
$$
Cov(Y) = Cov(X\beta + \epsilon) = Cov(\epsilon) = \sigma^2I_{n}
$$
\end{observación}
Veamos ahora cómo se pueden obtener los valores de los parámetros $\beta$.
\begin{definición}[Estimador por mínimos cuadrados]
Elegiremos los valores de $\beta$ que minimicen la suma de cuadrados:
$$
S =  \sum_{i=1}^n \epsilon_{i}^2 =  \sum_{i=1}^n (Y_{i}-\mu_{i})^2 = \sum_{i=1}^n (Y_{i}- (X\beta)_{i})^2
$$
Es decir: 
$$
\hat{\beta} = arg_{\beta \in \mathbb{R}^p}min{||Y-X\beta||^2}
$$
\label{minimos-cuadrados}
\end{definición}
Donde $||\cdot||$ denota la norma euclídea.
Para encontrar tal mínimo se razona derivando respecto de cada $\beta_i$ y luego igualando a 0. De este modo los parámetros $\beta_i$ vienen dados por la solución del siguiente sistema:

$$ \left\{
\begin{array}{ l }
\frac{\partial S}{\partial \beta_1}= 0 \\
\dots \\
\frac{\partial S}{\partial \beta_p}= 0
\end{array}
\right. 
$$
Desarrollando este sistema de escuaciones llegamos a que es equivalente a $X^TX\hat{\beta} = X^TY$, por lo que el estimador por mínimos cuadrados del vector de parámetros $\beta$ viene dado por:
$$
\hat{\beta} = (X^TX)^{-1}X^TY
$$
\begin{observación} Notemos que esta expresión tiene sentido pues el producto $X^TX$ resulta en una matriz cuadrada de orden p y rango máximo.
\end{observación}

\begin{proposición}[Distribución del estimador por mínimos cuadrados] 
El estimador por mínimos cuadrados del vector de parámetros $\beta$, $\hat{\beta}$, sigue una distribución del tipo normal p-variante de esperanza $\beta$ y matriz de covarianzas $V_{\hat{\beta}} = \sigma^2 (X^TX)^{-1}$. Es decir: 
$ \hat{\beta} \backsim N_{p}(\beta,\sigma^2 (X^TX)^{-1})$
\end{proposición}

\begin{proof}
Partiremos viendo que el estimador $\hat{\beta}$ es insesgado:
$$
E[\hat{\beta}] = E[(X^TX)^{-1}X^TY] = (X^TX)^{-1}X^TE[Y]=(X^TX)^{-1}X^TX \beta = \beta
$$
Por otro lado, calculemos  la matriz de covarianzas de $\hat{\beta}$, para ello primero debemos notar que como los errores aleatorios $\epsilon_i$ son independientes e identicamentes distribuidos con esperanza nula y varianza $\sigma^2$, $\forall i \neq j$:
$$
E[\epsilon_i \epsilon_j] = E[\epsilon_i] + E[\epsilon_j] + Cov(\epsilon_i, \epsilon_j) = 0 
$$
y, por tanto:
$$
E[\epsilon \epsilon^T] = 
E\begin{bmatrix}
\epsilon_1^2 & \epsilon_1 \epsilon_2 & \dotsb & \epsilon_1 \epsilon_n \\
\epsilon_1 \epsilon_2 & \epsilon_2^2 & \dotsb & \epsilon_2 \epsilon_n \\
\vdots &\vdots & \ddots & \vdots \\
\epsilon_1 \epsilon_n & \dotsb & \dotsb & \epsilon_n^2
\end{bmatrix}
= 
\begin{pmatrix}
E[\epsilon_1^2] & E[\epsilon_1 \epsilon_2] & \dotsb & E[\epsilon_1 \epsilon_n] \\
E[\epsilon_1 \epsilon_2] & E[\epsilon_2^2] & \dotsb & E[\epsilon_2 \epsilon_n] \\
\vdots &\vdots & \ddots & \vdots \\
E[\epsilon_1 \epsilon_n] & \dotsb & \dotsb & E[\epsilon_n^2]\end{pmatrix}
= 
\begin{bmatrix}
\sigma^2 & 0 & \dotsb & 0 \\
0 & \sigma^2 & \dotsb & 0 \\
\vdots &\vdots & \ddots & \vdots \\
0 & \dotsb & \dotsb & \sigma^2
\end{bmatrix}
$$
Luego, utilizando que $\hat{\beta} = \beta + (X^TX)^{-1}X \epsilon$, se tiene que: 
$$
Cov(\hat{\beta}) = E[(\hat{\beta} - E[\hat{\beta}])(\hat{\beta} - E[\hat{\beta}])^T] = 
E[(\hat{\beta} - \beta)(\hat{\beta} - \beta)^T] = 
E[((X^TX)^{-1}X^T \epsilon)((X^TX)^{-1}X^T \epsilon)^T] =\\
E[(X^TX)^{-1}X^T \epsilon \epsilon^T X(X^TX)^{-T}] = 
(X^TX)^{-1}X^T E[\epsilon \epsilon^T] X(X^TX)^{-T} =\\
(X^TX)^{-1}X^T \sigma^2 I_n X(X^TX)^{-T} = 
\sigma^2 (X^TX)^{-1}X^T X(X^TX)^{-T} =\sigma^2 (X^TX)^{-1}
$$
Acabamos la prueba recordando que $\hat{\beta}$ no es más que una combinación lineal de variables aleatorias normales, concretamente de las $Y_i$, para decir que en efecto sigue una distribución normal p-variante como indica el enunciado.
\end{proof}

\begin{observación}
Ahora bien, generalmente el valor de $\sigma^2$ es desconocido así que también sería preciso dar una estimación del mismo para que así los resultados anteriores fueran de alguna utilidad.
\end{observación}

\begin{definición}[Estimador de $\sigma^2$]
La varianza $\sigma^2$ admite un estimador insesgado que se basa en la suma de cuadrados:
$$
\hat{\sigma}^2 = \frac{S}{n-p}= \frac{\sum_{i=1}^n (Y_{i}- (X\beta)_{i})^2}{n-p}
$$
Además se tiene que $\hat{\sigma}^2$ sigue una distribución: 
$$
\hat{\sigma}^2 \backsim \frac{\sigma^2}{n-p}\chi^2_{n-p}
$$
\end{definición}

\begin{observación}
No daremos la obtención de este estimador pero sí indicaremos que su distribución se obtiene directamente de que como S es la suma de normales $N(0,\sigma^2)$ y $\frac{\epsilon_i}{\sigma} \backsim N(0,1)$, entonces: $\frac{1}{\sigma^2}S \backsim \chi^2_{n-p}$. Finalmente, multiplicando y dividiento esta expresión por (n-p) y sustituyendo la definición del estimador $\hat{\sigma}^2$ obtenemos el resultado.
\end{observación}

## Modelos lineales generalizados

Nos adentramos ya con esta sección en la primera extensión de los modelos lineales de las que se tratan durante el trabajo. Los Modelos Lineales Generalizados (MLG) fueron originalmente formulados por John Nelder y Robert Wedderburn (1972), quienes tenían como propósito unificar varios modelos estadísticos como la regresión lineal, la logística y la de Poisson en un mismo modelo. Este tipo de modelos relajan algunas de las condiciones de los modelos lineales, como que los errores ya no deben seguir ninguna distribución específica, y además añade nuevos elementos como la función de enlace, que interviene en la relación entre las medias y la forma lineal del modelo. También se deberá tener en cuenta que seguirá la hipótesis de que las variables de respuestas siguen distribuciones de tipo exponencial. Más tarde nos adentraremos en cada uno de estos aspectos, de momento demos la estructura básica de un MLG.

\begin{definición}[Estructura básica de un MLG]
$$
g(\mu) = X\beta
$$
$$
\mu = \begin{pmatrix} \mu_1 \\ \vdots \\ \mu_n \end{pmatrix} = 
\begin{pmatrix} E[Y_1] \\ \vdots \\ E[Y_n] \end{pmatrix} = E[Y]
$$
Donde: 
\begin{itemize}
  \item g es la función de enlace, que debe ser diferenciable y monótona.
  \item X es la matriz modelo que contiene a las variables predictoras, cada columna representa una variable predictora $X_i$.
  \item $\beta$ es el vector de parámetros desconocidos como en el caso de los modelos lineales.
  \item Y es el la variable de respuesta, se suele suponer que las $Y_i$ son independientes y que siguen una distribución de tipo exponencial.
\end{itemize}
\end{definición}

\begin{observación}
Desde esta formulación podemos ver fácilmente el por qué decimos que los MLG son una generalización de los modelos lineales, ya que basta tomar a la identidad como la función de enlace y suponer que la distribución considerada sea de tipo normal para encontrarnos ante la forma general de un modelo lineal como vimos en la sección anterior.
\end{observación}

### Familias de distribuciones exponenciales

Como hemos mencionado antes, la variable de respuesta de los modelos lineales generalizados deben seguir una distribución de tipo exponencial, en esta sección veremos qué significa eso y qué implicaciones tiene.

\begin{definición}[Distribución de tipo exponencial]
Una distribución se dice que es de tipo exponencial si su función de densidad es de la forma: 
$$
f_{\theta}(y) = e^{\frac{y\theta - b(\theta)}{a(\phi)}+c(y,\phi)}
$$
Donde: 
\begin{itemize}
  \item a, b y c son funciones arbitrarias.
  \item  $\phi$ es conocido como parámetro de escala.
  \item $\theta$ es conocido como parámetro canónico de la distribución. Más adelante veremos que depende completamente de los parámetros del modelo $\beta$.
\end{itemize}
\end{definición}

\begin{ejemplo}
La distribución normal es de tipo exponencial pues su función de densidad es:
$$
f_{\mu}(y) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(y-\mu)^2}{2\sigma^2}} = 
e^{\frac{-y^2+2y\mu-mu^2}{2\sigma^2}-log(\sigma\sqrt{2\pi})} = 
e^{\frac{y\mu-\mu^2/2}{\sigma^2}-\frac{y^2}{2\sigma^2}-log(\sigma\sqrt{2\pi})}
$$
Y por tanto toma los siguientes parámetros de la familia exponencial:
\begin{itemize}
  \item $\theta = \mu$
  \item $b(\theta) = \frac{\theta^2}{2} = \frac{\mu^2}{2}$
  \item $a(\phi) = \phi = \sigma^2$
  \item $c(\phi,y) = \frac{-y^2}{2\phi}-log(\sqrt{\phi 2 \pi}) = \frac{-y^2}{2\sigma} - log(\sigma \sqrt{2\pi})$
\end{itemize}
\end{ejemplo}

Es posible dar una forma general para la esperanza y la varianza de las variables de tipo exponencial dependiendo de los parámetros de su función de densidad. Lo vemos en el siguiente resultado.

\begin{proposición}
Sea Y una variable de tipo exponencial, entonces verifica:
\begin{itemize}
  \item $E[Y] = b'(\theta)$
  \item $Var(Y) = b''(\theta)a(\phi)$
\end{itemize}
\end{proposición}

\begin{proof}
Partimos considerando la función de verosimilitud logáritmica para $\theta$:
$$
l(\theta) = log(f_{\theta}(y)) = \frac{y\theta - b(\theta)}{a(\phi)} + c(y,\phi)
$$
Y su derivada respecto de theta: 
$$
\frac{\partial l}{\partial \theta}(\theta) =\frac{y-b'(\theta)}{a(\phi)} 
$$
Ahora bien, si cambiamos la observación y por la variable Y, podemos evaluar la esperanza de esta derivada, la cual será 0 por propiedades de la función de verosimilitud logáritmica.
$$
E[\frac{\partial l}{\partial \theta}(\theta)] = \frac{E[Y]-b'(\theta)}{a(\phi)} = 0
$$
Y de aquí se obtiene directamente que $E[Y] = b'(\theta)$.
Seguimos derivando para obtener que: 
$$
\frac{\partial^2 l}{\partial \theta^2}(\theta) =-\frac{b''(\theta)}{a(\phi)} 
$$
Y utilizando que: $E[\frac{\partial^2 l}{\partial \theta^2}] = -E[(\frac{\partial l}{\partial \theta})^2]$, nos queda que: 
$$
\frac{b''(\theta)}{a(\phi)} = \frac{E[(Y-b'(\theta))^2]}{a(\phi)^2} = \frac{E[(Y-E[Y])^2]}{a(\phi)^2} = \frac{Var(Y)}{a(\phi)^2}
$$
De donde se obtiene que: $Var(Y) = b''(\theta)a(\phi)$.
\end{proof}

\begin{observación}
Cuando $\phi$ es conocido el manejo de la función a no tiene dificultad, pero en muchos casos $\phi$ suele ser desconocido, así que para agilizar los resultados escribiremos $a(\phi) = \frac{\phi}{\omega}$, donde ${\omega}$ es una constante conocida. De hecho, todos los casos prácticos de interés se podrán expresar así y la mayoría con ${\omega}=1$. De este modo nos queda: $Var(Y) = b''(\theta)\frac{\phi}{\omega}$.
\end{observación}

